{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and graph performance summary statistics #\n",
    "\n",
    "** Author: Andrew Larkin **, Oregon State University College of Public Health and Human Sciences <br>\n",
    "** Date created: ** November 28, 2018\n",
    "\n",
    "### Summary ###\n",
    "Summary statistics image and remote sensing measures at PlacePulse image locations.  Operations include calculating summary statistics, plotting histograms and boxplots, and creating correlation matrices and correlation plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns; sns.set(color_codes=True) # note: do not import seaborn if you want outliers to show in boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define filepaths\n",
    "parentFolder = \"C:/users/larkinan/desktop/PlacePulse/\"#\"G:/dropbox/PlacePulse/\"\n",
    "measuresCSV = parentFolder + \"PlacePulseMergedMeasures_Dec13p3_18.csv\"\n",
    "addedConstructsCSV = parentFolder + \"PlacePulseMergedMeasures_Dec13p4_18.csv\"\n",
    "\n",
    "\n",
    "correlationVarsReduced = ['accessibility','allNature','animate','bluespace','building','builtEnv','car','grass','greenspace',\n",
    "                          'otherNature','person','plant','road','sidewalk','sky','tree','bench',\n",
    "                          'PM251000m','mjRds100m','NO2100m','tr100m','imp1000m','pop1000m','NDVI250m',\n",
    "                          'mu_beautiful','mu_lively','mu_safety']\n",
    "\n",
    "# variables to include in correlation matrix and correlation plot\n",
    "correlationVars = ['accessibility','allNature','animate','bluespace','building','builtEnv','car','grass','greenspace',\n",
    "                   'otherNature','person','plant','road','sidewalk','sky','tree','bench',\n",
    "                   'PM251000m','mjRds100m','mjRds250m','NO2100m','NO2250m','tr100m','tr250m','imp1000m','pop1000m',\n",
    "                   'NDVI250m',\n",
    "                   'mu_beautiful','mu_lively','mu_safety']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate statistics for one level in a stratificaiton ###\n",
    "function does not return statistics, but rather appends to already existing variable arrays.  One array corresponds to a single column in a denormalized database.\n",
    "**Inputs** <br>\n",
    "- **inputDataset** (pandas dataframe) - contains a large set of variables, including all variables of interest <br>\n",
    "- **stratifyVal** (string) - stratification level value <br>\n",
    "- **valueNames** (string array) - variables to calculate summary statistics for <br>\n",
    "- **stratifyName** (string array) - array designiating the stratify value for an index in all arrays <br>\n",
    "- **value** (string array) - array designating the variable category for an index in all arrays <br>\n",
    "- **meanVals** (float array) - mean value for the variable in value and stratification in stratifyNames <br>\n",
    "- **stdDev** (float array) - std dev for the variable in value and stratification in stratifyNames <br>\n",
    "- **minVal** (float aray) - min value for the variable in value and stratification in stratifyNames <br>\n",
    "- **maxVal** (float array) - max value for the variable in value and stratifcation in stratifyNames <br>\n",
    "- **iqr** (float array) interquartile range for the variable in value and stratification in stratifyNames <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcStatsOneStratify(inputDataset,stratifyVal,valueNames,\n",
    "                        stratifyName,value,meanVals,stdDev,minVal,maxVal,iqr):\n",
    "    \n",
    "    # for each varaible of interest, calculate summary statistics and append results to arrays\n",
    "    for valueName in valueNames:\n",
    "        stratifyName.append(stratifyVal)\n",
    "        value.append(valueName)\n",
    "        \n",
    "        npArr = np.array(inputDataset[valueName])\n",
    "        npArr = npArr[np.logical_not(np.isnan(npArr))]\n",
    "        meanVals.append(np.mean(npArr))\n",
    "        stdDev.append(np.std(npArr))\n",
    "        q75, q25 = np.percentile(npArr, [75 ,25])\n",
    "        minVal.append(np.min(npArr))\n",
    "        maxVal.append(np.max(npArr))\n",
    "        iqr.append(q75 - q25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate statistics, stratified by a specific variable ###\n",
    "**Inputs** <br>\n",
    "- **inputDataset** (pandas dataframe) - contains all variables and records of interest <br>\n",
    "- **valueNames** (string array) - names of the variables to calculate summary statistics for <br>\n",
    "- **stratify** (string) - name of the variable to stratify by <br>\n",
    "\n",
    "**Outputs** <br>\n",
    "- **df (pandas dataframe)** - contains derived summary statistics <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcSummaryStats(inputDataset,valueNames,stratify):\n",
    "    \n",
    "    # get set of all stratification levels\n",
    "    stratifyLevels = set(inputDataset[stratify])\n",
    "    stratifyName, value, meanVals, stdDev, minVal, maxVal, iqr  = ([] for i in range(7))\n",
    "    \n",
    "    # for each stratifcation level, get the subset partition of data \n",
    "    # and caculate summary statistics for the partition\n",
    "    for stratifyLevel in stratifyLevels:\n",
    "        subsetData = inputDataset.loc[inputDataset[stratify] == stratifyLevel]\n",
    "        calcStatsOneStratify(subsetData,stratifyLevel,valueNames,\n",
    "                            stratifyName,value,meanVals,stdDev,minVal,maxVal,iqr)\n",
    "        \n",
    "    # calculate summary statistics for the entire dataset, without stratification\n",
    "    calcStatsOneStratify(inputDataset,\"none\",valueNames,\n",
    "                        stratifyName,value,meanVals,stdDev,minVal,maxVal,iqr)\n",
    "    \n",
    "    # combine summary statistic arrays into a dict\n",
    "    statsDict = {stratify:stratifyName,'meanVals':meanVals,'stdDev':stdDev,'IQR':iqr,'value':value,\n",
    "                'min':minVal,'max':maxVal}\n",
    "    df = ps.DataFrame.from_dict(statsDict)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate 25th and 75th percentile for a subset of variables of interest ###\n",
    "**Inputs** <br>\n",
    "- **inputDataset** (pandas dataframe) - contains all variables of interest <br>\n",
    "- **categories** (string array) - names of the variables to calculate percentiles for <br>\n",
    "\n",
    "**Outputs** <br>\n",
    "- **outputDict** (dict) - dictionary containing 25th and 75th percentile for each variable of interest <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcLowHighQuartiles(inputDataset,categories):\n",
    "    outputDict = {}\n",
    "    \n",
    "    # for each variable of interest\n",
    "    for category in categories:\n",
    "        dataSubset = inputDataset[category]\n",
    "        dataSubset = dataSubset.dropna()\n",
    "        outputDict[category + \"low\"] = np.percentile(dataSubset, 25)\n",
    "        outputDict[category + \"high\"] = np.percentile(dataSubset,75)\n",
    "    return(outputDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate summary statistics for a specific subset of variables of interest.  For completing descriptive statistics in manuscript ###\n",
    "**Inputs** <br>\n",
    "- **inputDataset** (pandas dataframe) - contains all variables and records of interest <br>\n",
    "- **outputFilename** (string) - output filepath to write results to <br."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsetStatsForTable(inputDataset,outputFilename):\n",
    "    \n",
    "    # variables to calculate summary statistics for \n",
    "    tableCategories = ['accessibility','allNature','animate','bluespace','building','builtEnv','car','grass','greenspace',\n",
    "                       'otherNature','person','plant','road','sidewalk','sky','tree','person','bench',\n",
    "                       'PM251000m','mjRds100m','mjRds250m','NO2100m','NO2250m','tr100m','tr250m','imp1000m','pop1000m',\n",
    "                       'NDVI250m',\n",
    "                       'mu_beautiful','mu_lively','mu_safety','count_beautiful','win_beautiful','lose_beautiful',\n",
    "                       'count_lively','win_lively','lose_lively','count_safety','win_safety','lose_safety',\n",
    "                       'CITY_NAME']\n",
    "    \n",
    "    # subset dataset and calculate summary statistics\n",
    "    tableSubset = inputDataset[tableCategories]\n",
    "    tableCategories = tableCategories[0:len(tableCategories)-1]\n",
    "    subsetStats = calcSummaryStats(tableSubset,tableCategories,'CITY_NAME')\n",
    "    subsetStats.to_csv(outputFilename + \"_\" + str(len(tableSubset['CITY_NAME'])) + \".csv\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate summary statistics for the bottom and top quartile of perception variables ###\n",
    "**Inputs** <br>\n",
    "- **inputDataset** (pandas dataframe) - contains all variables and records of interest <br>\n",
    "- **parentFolder** (string) - name of the folder to write results to <br>\n",
    "- **valueNames** (string array) - names of the variables to calculate summary statistics for <br>\n",
    "- **stratify** (string) - name of the variable to stratify by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcLowHighSummaryStats(inputDataset,parentFolder,valueNames):\n",
    "    \n",
    "    # perception variables to calculate bottom and top percentile and partition by \n",
    "    percentileVars = ['mu_beautiful','mu_lively','mu_safety']\n",
    "    \n",
    "    # for each perception variable, calculate bottom and top quartile\n",
    "    lowHighDict = calcLowHighQuartiles(inputDataset,percentileVars)\n",
    "    \n",
    "    # for each perception variable, subset the bottom and top quartiles and calculate summary stats\n",
    "    for percentileVar in percentileVars:\n",
    "            lowSubset = inputDataset.loc[inputDataset[percentileVar] < lowHighDict[percentileVar + \"low\"]]\n",
    "            subsetStatsForTable(lowSubset,parentFolder + percentileVar + \"low\")\n",
    "            highSubset = inputDataset.loc[inputDataset[percentileVar] > lowHighDict[percentileVar + \"high\"]]\n",
    "            subsetStatsForTable(highSubset,parentFolder + percentileVar + \"high\")\n",
    "    print(lowHighDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a histogram for a single variable of interest.  Part of a larger plot of multiple variables ###\n",
    "**Inputs** <br>\n",
    "- **xMax** (int) - max value for the x axis <br>\n",
    "- **xVals** (float array) - values used to create histograms <br>\n",
    "- **subplotIndex** (int) - index of the larger plot where the subplot will be placed <br>\n",
    "- **yLabel** (string) - name of the y axis <br>\n",
    "- **xLabel** (string) - name of the x axis <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createHistogram(xMax,xVals,subplotIndex,yLabel,xLabel):\n",
    "    tempAxis = plt.subplot(5,2,subplotIndex)\n",
    "    tempAxis.set_xlim([min(xVals),xMax])\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.ylabel(yLabel)\n",
    "    n, bins, patches = plt.hist(xVals, 50,facecolor='g', alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot historgrams for multiple variables, stratified by a specific variable ### \n",
    "**Inputs** <br>\n",
    "- **inData** (pandas dataframe) - contains all variables and records of interest <br>\n",
    "- **outFolder** (string) - where histogram plots are saved <br>\n",
    "- **stratify** (string) - name of the variable containing stratification levels <br>\n",
    "- **valuesOfInterest** (string array) - name of the variables to create histograms for <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createHistograms(inData,outFolder,stratify,valuesOfInterest):\n",
    "    \n",
    "    # names of the stratification levels\n",
    "    stratifyLevels = set(inData[stratify])\n",
    "    \n",
    "    # for each stratification level, subset data by stratificatoin, and create a plot to store histograms\n",
    "    for stratifyLevel in stratifyLevels:\n",
    "        outputFile = outFolder + \"RemSensHist_\" + str(stratifyLevel) + \".png\"\n",
    "        if not(os.path.exists(outputFile)):\n",
    "            stratifySubset = inData.loc[inData[stratify] == stratifyLevel]\n",
    "            fig = plt.figure(num=None, figsize=(12, 15), dpi=160, facecolor='w', edgecolor='k')\n",
    "            fig.suptitle(\"Remote Sensing \" + stratifyLevel, fontsize=16)\n",
    "            index = 1\n",
    "            \n",
    "            # for each value of interest, create a histogram subplot\n",
    "            for value in valuesOfInterest:\n",
    "                subsetData = stratifySubset[value]\n",
    "                createHistogram(max(subsetData),subsetData,index,\"frequency\",value)\n",
    "                index+=1\n",
    "            plt.savefig(outFolder + \"RemSensHist_\" + str(stratifyLevel) + \".png\", bbox_inches=\"tight\")\n",
    "            \n",
    "    # create histograms for all data without stratification \n",
    "    stratifySubset = inData\n",
    "    fig = plt.figure(num=None, figsize=(12, 15), dpi=160, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"Remote Sensing \" + \"AllLevels\", fontsize=16)\n",
    "    index = 1\n",
    "    for value in valuesOfInterest:\n",
    "        subsetData = stratifySubset[value]\n",
    "        createHistogram(max(subsetData),subsetData,index,\"frequency\",value)\n",
    "        index+=1\n",
    "        plt.savefig(outFolder + \"RemSensHist_All.png\", bbox_inches=\"tight\")\n",
    "    \n",
    "    \n",
    "    #plt.show() # only use for debugging purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### createBoxplots for multiple variables, stratified by a specific variable ### \n",
    "**Inputs** <br>\n",
    "- **inData** (pandas dataframe) - contains all variables in the records of interest <br>\n",
    "- **outFolder** (string) - where boxplots are saved <br>\n",
    "- **stratify** (string) - name of the variable containing stratification levels <br>\n",
    "- **valuesOfInterest** (string array) - names of the variables to create boxplots for <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createBoxplots(inData,outFolder,stratify,valuesOfInterest):\n",
    "    \n",
    "    # names of the stratification levels\n",
    "    stratifyLevels = set(inData[stratify])\n",
    "    \n",
    "    # for each variable of interest, calculate summary statistics for each stratification level \n",
    "    for value in valuesOfInterest:\n",
    "        outputFile = outFolder + \"MeasBoxPlot_\" + value + \".png\"\n",
    "        if not os.path.exists(outputFile):\n",
    "            fig = plt.figure(num=None, figsize=(48, 15), dpi=160, facecolor='w', edgecolor='k')\n",
    "            fig.suptitle(\"Measure \" + value, fontsize=16)\n",
    "            boxData, medianVals, cityNames, cityNamesSorted, boxDataSorted  = ([] for i in range(5))\n",
    "            index=0\n",
    "        \n",
    "            for stratifyLevel in stratifyLevels:\n",
    "                stratifySubset = inData.loc[inData[stratify] == stratifyLevel]\n",
    "                stratifySubset = stratifySubset.dropna()\n",
    "                stratifySubset = stratifySubset[value]\n",
    "                boxData.append(stratifySubset)\n",
    "                medianVals.append((index,np.median(stratifySubset)))\n",
    "                cityNames.append(stratifyLevel)\n",
    "                index+=1\n",
    "                \n",
    "            # order the stratified summary statistics from low to high median\n",
    "            medianVals.sort(key=lambda x:x[1])\n",
    "            \n",
    "            for sortedMedian in medianVals:\n",
    "                boxDataSorted.append(boxData[sortedMedian[0]])\n",
    "                cityNamesSorted.append(cityNames[sortedMedian[0]])\n",
    "            plt.boxplot(boxDataSorted)\n",
    "            plt.xticks(range(1,len(cityNamesSorted)+1),cityNamesSorted,rotation=70)\n",
    "            #plt.show()\n",
    "            plt.savefig(outFolder + \"MeasBoxPlot_\" + value + \".png\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum multiple variables to create latent constructs ###\n",
    "**Inputs** <br>\n",
    "- **inData** (pandas dataframe) - contains all variables and records of interest <br>\n",
    "- **categories** (string array) - names of the variables to sum <br>\n",
    "- **categoryName** (string) - name to designate for the latent construct <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCategory(inData,categories,categoryName):\n",
    "    tempData = np.zeros((len(inData['wall']),1),dtype=float)\n",
    "    index=0\n",
    "    for category in categories:\n",
    "        tempData = np.add(tempData,np.array(inData[category],dtype=float).reshape(len(inData['wall']),1))\n",
    "    inData[categoryName] = tempData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create latent constructs by summing variables ###\n",
    "Adds latent constructs in place, nothing is returned from the function <br>\n",
    "**Inputs**<br>\n",
    "- **InData** (pandas dataframe) - contains all variables and records of interest <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCategories(inData):\n",
    "\n",
    "    # crate the built environment category\n",
    "    builtEnv = ['wall','building','road','windowpane','sidewalk','hovel','house','fence','railing',\n",
    "               'signboard','skyscraper','path','stairs','runway','screen', 'door', 'screen door','stairway',\n",
    "                'bridge','bench','booth','awning','streetlight','pole','bannister','escalator',\n",
    "               'fountain','swimming pool','step','sculpture','traffic light','pier','bulletin board']\n",
    "    createCategory(inData,builtEnv,'builtEnv')\n",
    "    \n",
    "    # create the accessibility category \n",
    "    accessibility = ['sidewalk','escalator','path','stairs','stairway','bench','step']\n",
    "    createCategory(inData,accessibility,'accessibility')\n",
    "    \n",
    "    # create the allNature category\n",
    "    allNature = ['tree','grass','plant','field','land','flower','water','sea','waterfall','lake','earth',\n",
    "                'mountain','rock','sky','sand','hill','dirt track']\n",
    "    createCategory(inData,allNature,'allNature')\n",
    "    \n",
    "    # create the greenspace cateogry \n",
    "    greenspace = ['tree','grass','plant','field','flower']\n",
    "    createCategory(inData,greenspace,'greenspace')\n",
    "    \n",
    "    # create the bluespace category \n",
    "    bluespace = ['water','sea','waterfall','lake']\n",
    "    createCategory(inData,bluespace,'bluespace')\n",
    "    \n",
    "    # create the otherNature category\n",
    "    otherNature = ['earth','mountain','rock','sky','sand','hill','dirt track','land']\n",
    "    createCategory(inData,otherNature,'otherNature')\n",
    "    \n",
    "    # create the animate category\n",
    "    animate = ['person','boat','car','bus','truck','airplane','van','ship','minibike','animal','bicycle']\n",
    "    createCategory(inData,animate,'animate')\n",
    "    \n",
    "    indoors = ['ceiling','chair','table','painting','sofa','shelf','desk','chest of drawers','counter',\n",
    "              'case','pool table','pillow','bookcase','coffee table','countertop','toilet',\n",
    "               'stove','kitchen island','swivel chair','chandelier','ottoman','buffet',\n",
    "              'cradle','microwave','dishwasher','plate','monitor','clock','rug']\n",
    "    \n",
    "    createCategory(inData,indoors,'indoors')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate correlations and create a correlation plot for the entire dataset ###\n",
    "**Inputs** <br>\n",
    "- **outFolder** (string) - name of the folder to store correlation matrix and correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCorrPlot(inData,outFolder):\n",
    "\n",
    "    correlationSubset = inData[correlationVarsReduced]\n",
    "    \n",
    "    # calculate correlations \n",
    "    corr = correlationSubset.corr()\n",
    "    fig = plt.figure(num=None, figsize=(48, 15), dpi=160, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    # create correlation plot\n",
    "    sns.clustermap(corr,cmap=\"coolwarm_r\")#, robust=True)\n",
    "    #plt.show()\n",
    "    plt.savefig(outFolder + \"CorrPlot.eps\")\n",
    "    plt.close()\n",
    "    #print(corr)\n",
    "    corr.to_csv(outFolder + \"corrMatrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reorder a set of observations based on the order of a separate array and normalize output ###\n",
    "\n",
    "**Inputs** <br>\n",
    "- **inDataset** (pandas dataframe) - contains all variables of interest <br>\n",
    "- **citySortOrder** (string array) - array of city names in order to sort dataset <br>\n",
    "- **attribute** (string) - name of the attribute to sort <br>\n",
    "\n",
    "**Outputs** <br>\n",
    "- **graphDict** (dict) - normalized mean and standard deviation of the attribute of interest, ordered by city array <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setSortOrder(inDataset, citySortOrder,attribute):\n",
    "    \n",
    "    stdDev, meanVals = ([] for i in range(2))\n",
    "    \n",
    "    # sort mean and standard deviation of variable of interst based on city name\n",
    "    for cityName in citySortOrder:\n",
    "        meanVals.append(float(inDataset[inDataset.CITY_NAME == cityName]['meanVals']))\n",
    "        stdDev.append(float(inDataset[inDataset.CITY_NAME == cityName]['stdDev']))\n",
    "    \n",
    "    # normalize mean and std dev of attribute\n",
    "    normVals = np.divide(np.subtract(meanVals,np.mean(meanVals)),np.std(meanVals))\n",
    "    stdDev = np.divide(stdDev,stdDev)\n",
    "    \n",
    "    graphDict = {'mean':normVals,'stdDev':stdDev,'city':citySortOrder}\n",
    "    return(graphDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate normalized mean and standard deviation of city level trends and plot in sorted order ###\n",
    "**Inputs** <br>\n",
    "- **attributes** (string array) - names of the variables to calc summary stats and plot.  The first string desginates the sort order of the plot.  The first attribute used to sort is not plotted <br>\n",
    "- **title** (string) - title to put on the graph <br>\n",
    "- **yLim** (float array) - min and max y limits <br>\n",
    "- **outputFilename** (string) - output filename of the graph.  Relative rather than absolute filepath. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotCityLevelTrends(attributes,title,yLim,outputFilename):\n",
    "    \n",
    "    # load city level estimates from csv\n",
    "    estimates = ps.read_csv(parentFolder + \"remoteSensingsummaryStats.csv\")\n",
    "    \n",
    "    graphDictArray, sortOrder, cityOrder, graphDict  = ([] for i in range(4))\n",
    "\n",
    "    for attribute in attributes:\n",
    "        attributeSubset = estimates[estimates.value == attribute]\n",
    "\n",
    "        # use the mean of the first attribute to determine the order of all attributes plotted in the graph\n",
    "        if(len(sortOrder) == 0):\n",
    "            sortOrder = attributeSubset.sort_values('meanVals')\n",
    "            cityOrder = list(sortOrder['CITY_NAME'])\n",
    "        else:\n",
    "            graphDictArray.append(setSortOrder(attributeSubset,cityOrder,attribute))\n",
    "                        \n",
    "    fig = figure(num=None, figsize=(14, 10), dpi=160, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    colorVec = ['#90ee90','#2f4b7c','#ffa500','#a05195','#d45087','#f95d6a','#ff7c43','#ffa600']\n",
    "    xVals = range(0,len(graphDictArray[0]['city']))\n",
    "    \n",
    "    numCities = len(xVals)\n",
    "    stepLen = numCities\n",
    "    numParams = len(graphDictArray)\n",
    "    \n",
    "    plt.xticks(np.arange(0, numCities + 1, step=stepLen))\n",
    "    \n",
    "    # for each attribute in the graph, plot the points and std dev bars\n",
    "    for i in range(0,len(attributes)-1):\n",
    "        currYVals = np.asarray(graphDictArray[i]['mean'])\n",
    "        currYVals = currYVals.reshape((len(xVals),))\n",
    "        yErrVals = np.asarray(graphDictArray[i]['stdDev']).reshape((len(xVals),))\n",
    "        currColor = colorVec[i]\n",
    "        plt.subplot()\n",
    "        plt.scatter( xVals, currYVals,label = attributes[i+1], alpha = 1.0, color=currColor)\n",
    "        plt.errorbar(xVals, currYVals, yerr=yErrVals, fmt='o',alpha = 0.4,color = currColor)\n",
    "        \n",
    "    plt.gca().set_ylim(yLim)\n",
    "    plt.legend()\n",
    "    plt.savefig(parentFolder + outputFilename, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate correlation between cities and graph the results in a correlation plot.  ###\n",
    "**Inputs** <br>\n",
    "- **attributes** (string array) - names of variables to include in the correlation matrix <br>\n",
    "- **outFolder** (string) - folderpath where the correlation matrix and plot will be stored <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcCityLevelCorr(attributes,outFolder):\n",
    "    # load city level estimates from csv\n",
    "    estimates = ps.read_csv(parentFolder + \"remoteSensingsummaryStats.csv\")\n",
    "    graphDictArray = []\n",
    "    \n",
    "    cityNames = list(set(estimates['CITY_NAME']))\n",
    "    cityDataset = ps.DataFrame(cityNames)\n",
    "    cityDataset.columns = (['CITY_NAME'])\n",
    "    cityDataset = cityDataset.sort_values('CITY_NAME')\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        attributeSubset = estimates[estimates.value == attribute]\n",
    "        attributeSubset = attributeSubset.sort_values('CITY_NAME')\n",
    "        attributeVals = list(attributeSubset['meanVals'])\n",
    "        cityDataset[attribute] = attributeVals\n",
    "    \n",
    "\n",
    "    \n",
    "    correlationSubset = cityDataset.drop(['CITY_NAME'],axis=1)\n",
    "    \n",
    "    # calculate correlations \n",
    "    corr = correlationSubset.corr()\n",
    "    fig = plt.figure(num=None, figsize=(48, 15), dpi=160, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    # create correlation plot\n",
    "    sns.clustermap(corr,cmap=\"coolwarm_r\")#, robust=True)\n",
    "    #plt.show()\n",
    "    plt.savefig(outFolder + \"CorrPlotCityLevel.eps\")\n",
    "    plt.close()\n",
    "    #print(corr)\n",
    "    corr.to_csv(outFolder + \"corrMatrixCity.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate average correlation within cities and graph the results in a correlation plot.  City averages are weighted by number of records ###\n",
    "**Inputs** <br>\n",
    "- **inData** (pandas dataframe) - dataset containing all variables of interest and city names <br>\n",
    "- **outFolder** (string) - name of the folder where the correlation plot will be stored <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcIntraCityCorr(inData,outFolder):\n",
    "    \n",
    "    cityNames = list(set(inData['CITY_NAME']))\n",
    "    cumulativeCorrSum = np.zeros((len(correlationVarsReduced),len(correlationVarsReduced)))\n",
    "\n",
    "    for city in cityNames:\n",
    "        \n",
    "        cityDataset = inData[inData.CITY_NAME == city]\n",
    "        cityDataset = cityDataset[correlationVarsReduced]\n",
    "        corr = cityDataset.corr()\n",
    "        \n",
    "        numCitySamples = len(cityDataset['animate'])\n",
    "        numVars = len(correlationVarsReduced)\n",
    "        \n",
    "        # for one city, there is no change in tr100 and, consequently NA correlation values.  This is to properly \n",
    "        # weight these values\n",
    "        numZeroCorrValues = np.isnan(corr)*numCitySamples\n",
    "\n",
    "        corr = np.nan_to_num(corr)\n",
    "        corrWeights = np.full((numVars,numVars),numCitySamples)\n",
    "        corrWegihts = np.subtract(corrWeights,numZeroCorrValues)\n",
    "        corr = np.multiply(corr,corrWeights)       \n",
    "        cumulativeCorrSum = np.add(corr,cumulativeCorrSum)\n",
    "\n",
    "    #print(len(inData['animate']))\n",
    "    avgCor = np.divide(cumulativeCorrSum,len(inData['animate']))\n",
    "    \n",
    "    #print(avgCor)\n",
    "    fig = plt.figure(num=None, figsize=(48, 15), dpi=160, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    # create correlation plot\n",
    "    sns.clustermap(avgCor,cmap=\"coolwarm_r\")#, robust=True)\n",
    "    #plt.show()\n",
    "    plt.savefig(outFolder + \"CorrPlotIntraCity2.eps\")\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # load data and clean\n",
    "    measuresData = ps.read_csv(measuresCSV)\n",
    "    removeVals = ['id','latit','longit','latJoin','longJoin','latitude','longitude','CITY_NAME',\n",
    "             'GMI_ADMIN','ADMIN_NAME','FIPS_CNTRY','CNTRY_NAME','STATUS','POP','POP_RANK','POP_CLASS']\n",
    "    \n",
    "    \n",
    "    screenedData = measuresData.dropna(subset=['wall']) \n",
    "    \n",
    "    # create latent constructs \n",
    "    createCategories(screenedData)\n",
    "    \n",
    "\n",
    "    valuesOfInterest = ([val for val in list(screenedData) if val not in removeVals])\n",
    "    \n",
    "    screenedData.to_csv(addedConstructsCSV)\n",
    "    \n",
    "    screenedData = screenedData[screenedData.indoors < 0.1]\n",
    "    print(\"numEntries after removing indoor outliers: %i\", len(screenedData['wall']))\n",
    "    \n",
    "    calculate summary stats\n",
    "    calcLowHighSummaryStats(screenedData,parentFolder,valuesOfInterest)\n",
    "    allSumStats = calcSummaryStats(screenedData,valuesOfInterest,'CITY_NAME')\n",
    "    allSumStats.to_csv(parentFolder + \"remoteSensingsummaryStats.csv\")\n",
    "    \n",
    "    create histograms, boxplots and correlation plots\n",
    "    #createHistograms(screenedData,parentFolder,'CITY_NAME',valuesOfInterest)\n",
    "    createBoxplots(screenedData,parentFolder,'CITY_NAME',valuesOfInterest)\n",
    "    createCorrPlot(screenedData,parentFolder)\n",
    "    calcCityLevelCorr(correlationVarsReduced,parentFolder)\n",
    "    calcIntraCityCorr(screenedData,parentFolder)\n",
    "      \n",
    "    plotCityLevelTrends(['mu_beautiful','mu_safety','mu_beautiful','mu_lively'],'construct scores',[-7.5,7.5],'constructScores.eps')\n",
    "    plotCityLevelTrends(['mu_beautiful','greenspace','NDVI250m','mu_beautiful'],'nature scores',[-7.5,7.5],'natureScores.eps')\n",
    "    plotCityLevelTrends(['mu_beautiful','road','mu_beautiful','mjRds100m','builtEnv'],'built env scores',[-7.5,7.5],'builtEnvScores.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
