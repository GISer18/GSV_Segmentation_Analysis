{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and graph time variance in image segmentation #\n",
    "\n",
    "** Author: Andrew Larkin **, Oregon State University College of Public Health and Human Sciences <br>\n",
    "** Date created: ** December 5th, 2018\n",
    "\n",
    "### Summary ###\n",
    "Google updates Street View Imagery on a regular basis.  This script estimates time variation in image segmentation estimates by calculating the relative standard deviation of imagery over time at each Place Pulse location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as ps\n",
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define global constants and filepaths\n",
    "\n",
    "parentFolder = \"C:/users/larkinan/desktop/tmpdlltr/\"\n",
    "comparisonFile = parentFolder + \"PulsePlaceComparisons.csv\"\n",
    "imageFolder = parentFolder + \"imageData/allImages/\"\n",
    "statsFile = parentFolder + \"imageDeviationStats.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load image-based estimates from a single csv file \n",
    "# (one csv file for each perception of interest - safety, lively, and beauty)\n",
    "def loadSingleImageFile(folder,index):\n",
    "    files = os.listdir(folder)\n",
    "    imageData = ps.read_csv(folder + files[index])\n",
    "    return(imageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCategory(inData,categories,categoryName):\n",
    "    tempData = np.zeros((len(inData['wall']),1))\n",
    "    index=0\n",
    "    for category in categories:\n",
    "        tempData = np.add(tempData,np.array(inData[category]).reshape(len(inData['wall']),1))\n",
    "    inData[categoryName] = tempData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create latent constructs by summing variables ###\n",
    "Adds latent constructs in place, nothing is returned from the function <br>\n",
    "**Inputs**<br>\n",
    "- **InData** (pandas dataframe) - contains all variables and records of interest <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCategories(inData):\n",
    "\n",
    "    # crate the built environment category\n",
    "    builtEnv = ['wall','building','road','windowpane','sidewalk','hovel','house','fence','railing',\n",
    "               'signboard','skyscraper','path','stairs','runway','screen door','stairway','bridge',\n",
    "               'bench','booth','awning','streetlight','television receiver','pole','bannister','escalator',\n",
    "               'fountain','swimming pool','step','sculpture','traffic light','pier']\n",
    "    createCategory(inData,builtEnv,'builtEnv')\n",
    "    \n",
    "    # create the accessibility category \n",
    "    accessibility = ['sidewalk','escalator','path','stairs','stairway','bench','step']\n",
    "    createCategory(inData,accessibility,'accessibility')\n",
    "    \n",
    "    # create the allNature category\n",
    "    allNature = ['tree','grass','plant','field','land','flower','water','sea','waterfall','lake','earth',\n",
    "                'mountain','rock','sky','sand','hill','dirt track']\n",
    "    createCategory(inData,allNature,'allNature')\n",
    "    \n",
    "    # create the greenspace cateogry \n",
    "    greenspace = ['tree','grass','plant','field','flower']\n",
    "    createCategory(inData,greenspace,'greenspace')\n",
    "    \n",
    "    # create the bluespace category \n",
    "    bluespace = ['water','sea','waterfall','lake']\n",
    "    createCategory(inData,bluespace,'bluespace')\n",
    "    \n",
    "    # create the otherNature category\n",
    "    otherNature = ['earth','mountain','rock','sky','sand','hill','dirt track','land']\n",
    "    createCategory(inData,otherNature,'otherNature')\n",
    "    \n",
    "    # create the animate category\n",
    "    animate = ['person','boat','car','bus','truck','airplane','van','ship','minibike','animal','bicycle']\n",
    "    createCategory(inData,animate,'animate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate relative standard deviation across time for each location ###\n",
    "**Inputs**<br>\n",
    "- **imageData** (pandas dataframe) - contains location key, image key, and image measures\n",
    "- **prevIDs** (string array) - ids of variables that already been processed\n",
    "**Outputs** <br>\n",
    "- **allStats** (np matrix) - relative std dev scores for all locations and image measures.  Rows correspond to unique measures, cols correspond to unique locations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcStats(imageData,prevIds):\n",
    "    allStats = None\n",
    "    index = 0\n",
    "    uniqueIds  = list(set(imageData['id']))\n",
    "    statsArray = []\n",
    "    for idVal in uniqueIds: \n",
    "        if(idVal not in prevIds):\n",
    "            subsetData = imageData.loc[imageData['id'] == idVal]\n",
    "            stdArr = np.std(subsetData,axis=0)*100.0\n",
    "            meanArr = np.mean(subsetData,axis=0)\n",
    "            subsetStats = np.divide(stdArr,meanArr)\n",
    "            subsetStats = subsetStats.reshape((subsetStats.shape[0],1))\n",
    "            statsArray.append(subsetStats)\n",
    "            index+=1\n",
    "            if(index==1000):\n",
    "                print(index)\n",
    "    allStats = np.stack(statsArray,axis=1)\n",
    "    return(allStats)                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleanup relative standard deviation dataset ###\n",
    "**Inputs** <br>\n",
    "- **allStats** (np arrray) - measures to calculate relative standard deviation for <br>\n",
    "- **imageData** (pandas dataframe) - contains variables names location ids <br>\n",
    "\n",
    "**Outputs** <br>\n",
    "- **cleanedRelStdDev** (pandas dataframe) - relative standard deviation with column names added, and locations with missing data removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanRelStdDev(allStats,imageData):\n",
    "    relStdDev = ps.DataFrame(allStats.reshape(allStats.shape[0],allStats.shape[1]))\n",
    "    relStdDev = relStdDev.T\n",
    "    subsetData = imageData.loc[imageData['id'] == imageData['id'][0]]\n",
    "    stdArr = np.std(subsetData,axis=0)*100.0\n",
    "    relStdDev.columns = stdArr.keys()\n",
    "    uniqueIds  = list(set(imageData['id']))\n",
    "    relStdDev['id'] = uniqueIds\n",
    "    cleanedRelStdDev = relStdDev[np.isfinite(relStdDev['wall'])]\n",
    "    return(cleanedRelStdDev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate relative standard deviation of image based measures for each image dataset (safety, beauty, and lively) ###\n",
    "**Inputs** <br>\n",
    "- **imageFolder** (string) - filepath to folder containing datasets to process <br>\n",
    "- **imageIndex** (int) - image dataset number <br>\n",
    "- **prevIDs** (string array) - ids of previously processed images <br>\n",
    "\n",
    "**Outputs** <br>\n",
    "- **cleanedRelStdDev** (pandas dataframe) - relative standard deviation estimates for the input dataset <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processSingleImageSet(imageFolder,imageIndex,prevIDs):\n",
    "    \n",
    "    keepVars = ['lat','lng','id',\n",
    "                'wall','building','road','windowpane','sidewalk','hovel','house','fence','railing',\n",
    "                'signboard','skyscraper','path','stairs','runway','screen door','stairway','bridge',\n",
    "                'bench','booth','awning','streetlight','television receiver','pole','bannister','escalator',\n",
    "                'fountain','swimming pool','step','sculpture','traffic light','pier',\n",
    "                'tree','grass','plant','field','land','flower','water','sea','waterfall','lake','earth',\n",
    "                'mountain','rock','sky','sand','hill','dirt track',\n",
    "                'person','boat','car','bus','truck','airplane','van','ship','minibike','animal','bicycle',\n",
    "                'builtEnv','accessibility','allNature','greenspace','bluespace','otherNature','animate']\n",
    "    \n",
    "    keepVars = list(set(keepVars)) # clean up check\n",
    "    \n",
    "    imageData = loadSingleImageFile(imageFolder,imageIndex)\n",
    "    createCategories(imageData)   \n",
    "    imageData2 = imageData[keepVars]\n",
    "    createCategories(imageData)\n",
    "    allStats = calcStats(imageData,[])\n",
    "    \n",
    "    cleanedRelStdDev = cleanRelStdDev(allStats,imageData)\n",
    "    \n",
    "    return(cleanedRelStdDev)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset1 = processSingleImageSet(imageFolder,0,[])\n",
    "    collectedIDs = dataset1['id']\n",
    "    dataset2 = processSingleImageSet(imageFolder,1,collectedIDs)\n",
    "    collectedIDs = collectedIDs + dataset2['id']\n",
    "    dataset3 = processSingleImageSet(imageFolder,2,collectedIDs)\n",
    "    combinedData = ps.concat([imageData4,imageData5,imageData3])\n",
    "    combinedData.to_csv(statsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
